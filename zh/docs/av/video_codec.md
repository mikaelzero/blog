视频中图像一般是 YUV 格式。现在，我们假设有一个电影视频，分辨率是 1080P，帧率是 25fps，并且时长是 2 小时，如果不做视频压缩的话，它的大小是 1920 x 1080 x 1.5 x 25 x 2 x 3600 = 260.7G,所以，我们需要对视频进行编码压缩

## 视频编码的原理

一般我们所熟知的彩色图像的格式是 RGB 的。但是，RGB 三个颜色是有相关性的，为了去掉这个相关性，减少需要编码的信息量，我们通常会把 RGB 转换成 YUV

相关性是指一幅图像在 RGB 格式的时候，将 R、G、B 三个通道分离开来当作图像来看的话，R、G、B 三张图像内容几乎是一样的，只是颜色不同而已。具有相关性，如果拿来编码的话，三张图像同等重要，而且轮廓还差不多，但颜色又不同，因此不好编码。而 YUV 不同，YUV 中只有 Y 是图像的大体轮廓，没有颜色信息。U、V 是颜色信息。三张图像相互独立。并且人眼对于色彩信息相比图像的轮廓信息不敏感些。我们可以缩小 U、V 的大小，比如 YUV420 中 U、V 只有 Y 的 1/4 大小，本身就相比于 RGB 图像小了一半。然后我们编码的时候 Y、U、V 相关性很小，可以独立编码，也很方便。

视频压缩算法要做两件重要的事（如在 H.264/AVC、HEVC、VP9 和 AV1 等编解码器中）：

使用 DCT（Discrete Cosine Transform，离散余弦变换）将“像素域”转换为“频域”。如果你还不了解什么是 DCT，可以看下这篇文章（[如何给 5 岁孩子解释 DCT？](https://mp.weixin.qq.com/s?__biz=MzU1NTEzOTM5Mw==&mid=2247513696&idx=1&sn=1ed871393a85e35177879cf6eb91ce3b&chksm=fbda1e4eccad9758e2883f178e09f9a225cdae38b7fd5c92527cabe0f71adfba5ab28a62a76f&scene=21#wechat_redirect)）。

通过一种被称为量化的技术舍弃一些频域数据（被称为系数），同时确保人眼无法感知这种数据丢失。

如果一个视频是纯色的且不会改变，在压缩的时候，你会怎么设计？当然是只存一个颜色值，然后其他位置都用同一个颜色值；如果一个视频只有一部分在改变，那就找到一个算法，来减少不动区域的开销。所谓编码算法，就是寻找规律，构建模型。谁能找到更精准的规律，建立更高效的模型，谁就是厉害的算法。

## 数据冗余

图像一般都是有数据冗余的，主要包括以下 4 种:

- 空间冗余。比如说将一帧图像划分成一个个 16x16 的块之后，相邻的块很多时候都有比较明显的相似性，这种就叫空间冗余。
- 时间冗余。一个帧率为 25fps 的视频中前后两帧图像相差只有 40ms，两张图像的变化 是比较小的，相似性很高，这种叫做时间冗余。
- 视觉冗余。我们的眼睛是有视觉灵敏度这个东西的。人的眼睛对于图像中高频信息的敏 感度是小于低频信息的。有的时候去除图像中的一些高频信息，人眼看起来跟不去除高 频信息差别不大，这种叫做视觉冗余。
- 信息熵冗余。我们一般会使用 Zip 等压缩工具去压缩文件，将文件大小减小，这个对于 图像来说也是可以做的，这种冗余叫做信息熵冗余。视频编码就是通过减少上述 4 种冗余来达到压缩视频的目的。

![](https://raw.githubusercontent.com/mikaelzero/ImageSource/main/uPic/p8pKPV.png)

## GOP

将一串连续的相似的帧归到一个图像群组（Group Of Pictures，GOP）

不同的帧如何编码和解码的

**I 帧**

- （I Picture、I Frame、 Intra Coded Picture），译为：帧内编码图像，也叫关键帧（Keyframe）
- 它是视频的第一帧，也是 GOP 的第一帧
- 编码：对整帧图片数据进行编码
- 解码：仅用当前 I 帧的编码数据就可以解码出完整的图像
- 是一种自带全部信息的独立帧，无需参考其他图像便可以独立进行解码，可以简单理解为一张静态图像

**P 帧**

- P 帧（P Picture、P Frame、Predictive Coded Picture），翻译为：预测编码图像
- 编码： ① 并不会对整帧图像数据进行编码 ② 以前面的 I 帧或 P 帧作为参考帧，只编码当前 P 帧与参考帧的差异数据
- 解码：需要先解码出前面的参考帧，再结合差异数据解码出当前 P 帧完整的图像
